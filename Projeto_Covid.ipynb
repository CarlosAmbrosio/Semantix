{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Enviar os dados para o hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Fazer o download do arquivo no diretório input do SPARK (comandos rodados no terminal Linux)\n",
    "    \n",
    "sudo mkdir spark/input/covid\n",
    "cd covid\n",
    "sudo curl -O https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/PNI/vacina/uf/2021-11-05/uf%3DSP/part-00000-aa6d7a64-f91d-43b4-afe9-09bc6c16a91e.c000.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     b. O arquivo baixado foi enviado para o hdfs (comandos rodados no terminal Linux)\n",
    "     \n",
    "hdfs dfs -put /input/covid/part-00000-aa6d7a64-f91d-43b4-afe9-09bc6c16a91e.c000.csv /user/carlos/projeto/\n",
    "\n",
    "    c. O arquivo foi renomeado para facilitar a codificação do projeto (comandos rodados no terminal Linux)\n",
    "   \n",
    "hdfs dfs -mv /user/carlos/data/part-00000-aa6d7a64-f91d-43b4-afe9-09bc6c16a91e.c000.csv /user/carlos/projeto/covid.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: `/user/carlos/projeto/covid.csv': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# Confirmação da cópia e renomeação do arquivo.\n",
    "\n",
    "!hdfs dfs -ls /user/carlos/projeto/covid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5bc1e517b56ccffc2c131f6a3d680739cf4a9c7f8283\";\"58\";\"1963-01-23\";\"M\";\"99\";\"SEM INFORMACAO\";\"355030\";\"10\";\"SAO PAULO\";\"BRASIL\";\"SP\";\"\";\"B\";\"2028840\";\"SECRETARIA DE ESTADO DA SAUDE DE SAO PAULO\";\"INSTITUTO DE INFECTOLOGIA EMILIO RIBAS SAO PAULO\";\"355030\";\"SAO PAULO\";\"SP\";\"000111\";\"Outros Imunocomprometidos\";\"\";\"Comorbidades\";\"215VCD129Z\";\"ASTRAZENECA/FIOCRUZ\";\"\";\"2021-08-05\";\"2ª Dose\";\"85\";\"COVID-19 ASTRAZENECA/FIOCRUZ - COVISHIELD\";\"VACIVIDA\";\"2021-08-05T03:08:00.000Z\";\"18262\"\r\n",
      "\"8655f271-c75b-4aac-9ac4-01a32172376e-i0b0\";\"7ef5bfcc7a1736da2b7ee9b20037e565306020b486f3e4f5fc9ebb9f65afc725\";\"63\";\"1957-08-10\";\"M\";\"99\";\"SEM INFORMACAO\";\"355030\";\"10\";\"SAO PAULO\";\"BRASIL\";\"SP\";\"03514\";\"B\";\"2786923\";\"PREFEITURA DO MUNICIPIO DE SAO PAULO\";\"UBS CIDADE PATRIARCA DR HERMENEGILDO MORBIN JUNIOR\";\"355030\";\"SAO PAULO\";\"SP\";\"000201\";\"Pessoas de 18 a 64 anos\";\"2\";\"Faixa Etária\";\"210183\";\"ASTRAZENECA/FIOCRUZ\";\"\";\"2021-07-28\";\"2ª Dose\";\"85\";\"COVID-19 ASTRAZENECA/FIOCRUZ - COVISHIELD\";\"VACIVIDA\";\"2021-07-28T03:07:00.000Z\";\"18262\"\r\n"
     ]
    }
   ],
   "source": [
    "# Visualização do arquivo.\n",
    "\n",
    "!hdfs dfs -tail /user/carlos/projeto/covid.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Otimizar todos os dados do hdfs para uma tabela Hive particionada por município."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Acessar o serviço hive-server (comandos rodados no terminal Linux)\n",
    "docker exec -it hive-server bash\n",
    "\n",
    "    b. Conectar o hive-serve utilizando o Beeline (comandos rodados no terminal Linux):\n",
    "beeline -u 'jdbc:hive2://localhost:10000 -uroot'\n",
    "\n",
    "    c. Verificar os databases e criar o database \"vacinacao\" e a tabela \"vacinasp\" (comandos rodados no terminal Linux):\n",
    "show databases;\n",
    "create database vacinacao;\n",
    "use vacinacao;\n",
    "create external table vacinasp\n",
    "    (\n",
    "    document_id varchar(50) comment 'ID do Documento do Paciente', \n",
    "    paciente_id varchar(60) comment 'ID do Paciente', \n",
    "    paciente_idade smallint comment 'Idade do Paciente', \n",
    "    paciente_data_nasc string, \n",
    "    paciente_enumSexoBiologico varchar(1) comment 'Sexo do Paciente', \n",
    "    paciente_raca_cod smallint, \n",
    "    paciente_raca_valor string, \n",
    "    paciente_cod_municipio int comment 'Codigo do Municipio', \n",
    "    paciente_pais int, \n",
    "    paciente_municipio string comment 'Nome do Municipio', \n",
    "    paciente_pais_nome string, \n",
    "    paciente_uf string, \n",
    "    paciente_cep string, \n",
    "    paciente_nacionalidade string, \n",
    "    estabelecimento_valor int, \n",
    "    estabelecimento_razao string, \n",
    "    estabelecimento_fantasia string, \n",
    "    estabelecimento_cod_mun int, \n",
    "    estabelecimento_municipio string comment 'Municipio de Aplicacao da Vacina', \n",
    "    estabelecimento_uf string, \n",
    "    vacina_grupo_cod int comment 'Codigo do Grupo Vacinal', \n",
    "    vacina_grupo_nome varchar(30) comment 'Nome do Grupo Vacinal', \n",
    "    vacina_categoria_cod int, \n",
    "    vacina_categoria_nome string, \n",
    "    vacina_lote string, \n",
    "    vacina_fabricante_nome varchar(30) comment 'Fabricante da Vacina', \n",
    "    vacina_fabricante_ref string, \n",
    "    vacina_dataAplicacao date comment 'Data de Aplicacao da Vacina', \n",
    "    vacina_descricao_dose string comment 'Numero da Dose', \n",
    "    vacina_cod int, \n",
    "    vacina_nome varchar(50) comment 'Nome da Vacina', \n",
    "    sistema_origem string, \n",
    "    time_stamp string, \n",
    "    desconhecido string \n",
    "    ) \n",
    "    row format delimited \n",
    "    fields terminated by ';' \n",
    "    lines terminated by '\\n' \n",
    "    location '/user/carlos/projeto/'\n",
    "    tblproperties('skip.header.line.count'='1')\n",
    "    ;\n",
    "    \n",
    "    d. Criar tabela particionada por municipio (comandos rodados no terminal Linux):\n",
    "\n",
    "create external table vacinasp_part\n",
    "    (\n",
    "    document_id varchar(50) comment 'ID do Documento do Paciente', \n",
    "    paciente_id varchar(60) comment 'ID do Paciente', \n",
    "    paciente_idade smallint comment 'Idade do Paciente', \n",
    "    paciente_enumSexoBiologico varchar(1) comment 'Sexo do Paciente',\n",
    "    paciente_cod_municipio int comment 'Codigo do Municipio', \n",
    "    vacina_grupo_cod int comment 'Codigo do Grupo Vacinal',\n",
    "    vacina_grupo_nome varchar(30) comment 'Nome do Grupo Vacinal', \n",
    "    vacina_fabricante_nome varchar(30) comment 'Fabricante da Vacina', \n",
    "    vacina_dataAplicacao date comment 'Data de Aplicacao da Vacina', \n",
    "    vacina_descricao_dose string comment 'Numero da Dose',\n",
    "    vacina_nome varchar(50) comment 'Nome da Vacina'\n",
    "    ) \n",
    "    partitioned by (estabelecimento_municipio string comment 'Municipio de Aplicacao da Vacina')\n",
    "    location '/user/carlos/projeto/'\n",
    "    ;\n",
    "    \n",
    "    e. Inserir dados (comandos rodados no terminal Linux)\n",
    "    \n",
    "insert overwrite table vacinasp_part partition (estabelecimento_municipio) \n",
    "    select document_id, \n",
    "            paciente_id, \n",
    "            paciente_idade, \n",
    "            paciente_enumSexoBiologico, \n",
    "            paciente_cod_municipio, \n",
    "            estabelecimento_municipio,\n",
    "            vacina_grupo_cod, \n",
    "            vacina_grupo_nome, \n",
    "            vacina_fabricante_nome, \n",
    "            vacina_dataAplicacao, \n",
    "            vacina_descricao_dose, \n",
    "            vacina_nome \n",
    "    from vacinasp;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Criar as 3 vizualizações pelo Spark com os dados enviados para o HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Salvar a primeira visualização como tabela Hive\n",
    "5. Salvar a segunda visualização com formato parquet e compressão snappy\n",
    "6. Salvar a terceira visualização em um tópico no Kafka\n",
    "7. Criar a visualização pelo Spark com os dados enviados para o HDFS\n",
    "8. Salvar a visualização do exercício 6 em um tópico no Elastic\n",
    "9. Criar um dashboard no Elastic para visualização dos novos dados enviados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
